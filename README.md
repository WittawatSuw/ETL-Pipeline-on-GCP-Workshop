ETL Pipeline on GCP Workshop (Road to Data Engineer Course, DataTH School, 2024)

- Developed a robust ETL pipeline on GCP using Apache Airflow to automate data extraction, transformation, and loading (ETL) processes, processing over 540,000 retail transaction records.

- Extracted data from multiple heterogeneous sources (e.g., MySQL, API), transformed it into a standardized, analysis-ready format using Python, Pandas, and PySpark, and then loaded it into BigQuery.

- Implemented rigorous data cleaning and validation procedures to ensure data quality and integrity across large-scale datasets.

- Designed and built interactive dashboards in Looker Studio (formerly Google Data Studio) from BigQuery data, consisting of three key sections: 

    - Sales Performance: Displaying revenue data, including total revenue, number of items sold, revenue trends, % of best-selling items, and revenue by country.
     
    - Customer Insights: Presenting customer data, such as total customers, average revenue per customer purchase, monthly customer trends, frequency of spending for frequent buyers, and a table of top-spending  customers.
     
    - Product Search: Allowing users to search for products based on desired sales performance.

- Medium:Project documentation available on [Medium](https://medium.com/@wittawatsuwannarak/%E0%B8%81%E0%B8%B2%E0%B8%A3%E0%B8%97%E0%B8%B3-data-pipeline-%E0%B8%88%E0%B8%B2%E0%B8%81%E0%B8%84%E0%B8%AD%E0%B8%A3%E0%B9%8C%E0%B8%AA-r2de-b5ab385649e8)
